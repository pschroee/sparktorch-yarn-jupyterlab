{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b813ce3-3dd1-40e9-bb03-5060c15116a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, column\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from sparktorch import PysparkPipelineWrapper\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40216717-806e-4dc2-bc88-f6e8dcfa87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting configuration\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"yarn\")\n",
    "sparkConf.setAppName(\"MNIST_TEST\")\n",
    "sparkConf.set(\"spark.hadoop.yarn.resourcemanager.address\", \"127.0.0.1:8032\")\n",
    "sparkConf.set(\"spark.driver.memory\",\"2g\").set(\"spark.executor.memory\", '2g').set('spark.executor.cores', 2)\n",
    "#sparkConf.setMaster(\"local[2]\").set(\"spark.driver.memory\",\"8g\").set(\"spark.executor.memory\", '8g').set('spark.executor.cores', 1)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fbd50-b3a2-4272-a7ef-f0df43892435",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"schema.json\") as f:\n",
    "    schema = StructType.fromJson(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855085c1-f822-4c73-ad9e-ec60356664fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('/user/hduser/input/mnist_test.csv') \\\n",
    "    .withColumnRenamed(\"_c0\", \"labels\") \\\n",
    "    .coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9e15d-364c-4db8-8c93-a71f5de59cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ml pipeline from hdfs\n",
    "p = PysparkPipelineWrapper.unwrap(PipelineModel.load(\"/user/hduser/models/mnist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c401d-2d58-491d-844b-d7a6c1c7eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = p.transform(df).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a06ee-fbbb-4b61-a1da-38cb319dbaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labels\", predictionCol=\"predictions\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Train accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f02d03-ef09-4c57-ad06-e8a7579d76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all images where the prediction was wrong\n",
    "compare = np.array(predictions.select(col(\"labels\"), col(\"predictions\")).collect()).reshape(10000,2)\n",
    "# Insert index column for getting image data\n",
    "compare = np.insert(compare, 0, np.array(list(range(10000))), axis=1)\n",
    "wrongPredictions = []\n",
    "for item in compare:\n",
    "    if (item[1] != item[2]):\n",
    "        wrongPredictions.append([int(item[0]), item[1], item[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75ce60-16f5-408c-ac15-01d8299184aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrongPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479096ca-d6ba-4a5b-84c3-8fff1cd7df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wrong identified images\n",
    "num_col = 10\n",
    "\n",
    "num_row = int((len(wrongPredictions) - (len(wrongPredictions) % num_col)) / num_col) + 1\n",
    "images = np.array(df.drop(col(\"labels\")).collect()).reshape(10000,28,28)\n",
    "\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "\n",
    "for i in range(num_row * num_col):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "for i in range(len(wrongPredictions)):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.set_axis_on()\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(images[wrongPredictions[i][0]], cmap='gray_r')\n",
    "    ax.set_title('Prediction: {}'.format(int(wrongPredictions[i][2])))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb199d-cffb-4d5a-afed-f9b2aef516a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cce37-0e59-4ba2-a69b-53982290ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
