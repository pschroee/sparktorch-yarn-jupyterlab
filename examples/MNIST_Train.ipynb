{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999685ce-5ed0-41ce-879b-b196b5bf2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparktorch import serialize_torch_obj, SparkTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.sql.functions import col, udf, column\n",
    "import json\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e8e87-f436-4443-b32f-2cdc8c2df72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting configuration\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"yarn\")\n",
    "sparkConf.setAppName(\"MNIST_TRAIN\")\n",
    "sparkConf.set(\"spark.hadoop.yarn.resourcemanager.address\", \"127.0.0.1:8032\")\n",
    "sparkConf.set(\"spark.driver.memory\",\"6g\").set(\"spark.executor.memory\", '6g').set('spark.executor.cores', 2)\n",
    "#sparkConf.setMaster(\"local[2]\").set(\"spark.driver.memory\",\"8g\").set(\"spark.executor.memory\", '8g').set('spark.executor.cores', 1)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441ac49-fe29-49df-ba60-14f6e2267882",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"schema.json\") as f:\n",
    "    schema = StructType.fromJson(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f971a-a8e7-4c3c-8f0f-a90429b2b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('/user/hduser/input/mnist_train.csv') \\\n",
    "    .withColumnRenamed(\"_c0\", \"labels\") \\\n",
    "    .coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfd28b-21da-4e29-96ee-ac0e029ca953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of record\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b63b95-2e48-4d36-b069-693e9dffdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e53dbc-9bfb-4761-b4ee-de46c6e7faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pytorch object\n",
    "torch_obj = serialize_torch_obj(\n",
    "    model=network,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db2068-36e8-4489-8d41-0ee4833bdc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup features\n",
    "vector_assembler = VectorAssembler(inputCols=df.columns[1:785], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8184cb3-976c-4299-9a65-a6c4e8fd9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkTorch Model with torch distributed. Barrier execution is on by default for this mode.\n",
    "spark_model = SparkTorch(\n",
    "    inputCol='features',\n",
    "    labelCol='labels',\n",
    "    predictionCol='predictions',\n",
    "    torchObj=torch_obj,\n",
    "    iters=200,\n",
    "    verbose=1,\n",
    "    miniBatch=256,\n",
    "    earlyStopPatience=40,\n",
    "    validationPct=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4fbbb-388b-4a40-9a41-551db4142955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and create a pipeline\n",
    "p = Pipeline(stages=[vector_assembler, spark_model]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699dba12-e14a-4527-a189-e853021a0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "predictions = p.transform(df).persist()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labels\", predictionCol=\"predictions\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Train accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf401d-1487-48bc-9c1b-47a94a9cd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline in hdfs\n",
    "p.write().overwrite().save('/user/hduser/models/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43859432-9b86-48c8-8174-14b23d4e044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e317693-0822-44ce-8376-1ecedf5df40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
